{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn import metrics\n",
    "import myfm\n",
    "from myfm import RelationBlock\n",
    "import pandas as pd\n",
    "from scipy import sparse as sps\n",
    "from mapper import DefaultMapper\n",
    "\n",
    "# read movielens 100k data.\n",
    "from movielens100k_data import MovieLens100kDataManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_manager = MovieLens100kDataManager()\n",
    "df_train, df_test = data_manager.load_ranking(fold=3)\n",
    "\n",
    "user_info = data_manager.load_userinfo().set_index('user_id')\n",
    "user_info['age'] = user_info.age // 5 * 5\n",
    "user_info['zipcode'] = user_info.zipcode.str[0]\n",
    "\n",
    "user_info_ohe = OneHotEncoder(handle_unknown='ignore').fit(user_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_to_internal = DefaultMapper(df_train.user_id.values)\n",
    "movie_to_internal = DefaultMapper(df_train.movie_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_be = OneHotEncoder(handle_unknown='ignore').fit(\n",
    "    df_train.timestamp.dt.date.values.reshape(-1, 1)\n",
    ")\n",
    "def categorize_date(df):\n",
    "    return date_be.transform(df.timestamp.dt.date.values[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_date_train = categorize_date(df_train)\n",
    "X_date_test  = categorize_date(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement flavor of SVD++\n",
    "\n",
    "We add \"all users who have evaluated a movie in the train set\" as the movie's feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_vs_watched = dict()\n",
    "for row in df_train.itertuples():\n",
    "    user_id = row.user_id\n",
    "    movie_id = row.movie_id\n",
    "    movie_vs_watched.setdefault(movie_id, list()).append(user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_group_sizes = [\n",
    "    len(date_be.categories_[0]) # date\n",
    "] + [\n",
    "    len(user_to_internal) # user ids\n",
    "] + [\n",
    "    len(c) for c in user_info_ohe.categories_ # user attributes\n",
    "] + [\n",
    "    len(movie_to_internal), # movie ids\n",
    "    len(user_to_internal) # all users who watched the movies\n",
    "]\n",
    "\n",
    "grouping = [ i for i, size in enumerate(feature_group_sizes) for _ in range(size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given user/movie ids, add additional infos and return it as sparse\n",
    "def augment_user_id(user_ids):\n",
    "    X = sps.lil_matrix((len(user_ids), len(user_to_internal)))\n",
    "    for index, user_id in enumerate(user_ids):\n",
    "        X[index, user_to_internal[user_id]] = 1\n",
    "    return sps.hstack(\n",
    "        [X.tocsr(), user_info_ohe.transform(user_info.reindex(user_ids))],\n",
    "        format='csr'\n",
    "    )\n",
    "\n",
    "def augment_movie_id(movie_ids):\n",
    "    X = sps.lil_matrix((len(movie_ids), len(movie_to_internal)+len(user_to_internal)))\n",
    "    for index, movie_id in enumerate(movie_ids):\n",
    "        X[index, movie_to_internal[movie_id]] = 1\n",
    "        watched_users = movie_vs_watched.get(movie_id, [])\n",
    "        normalizer = 1 / max(len(watched_users), 1) ** 0.5\n",
    "        for uid in watched_users:\n",
    "            X[index, user_to_internal[uid] + len(movie_to_internal)] = normalizer\n",
    "    return X.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_and_index(keys):\n",
    "    unique_keys = np.unique(keys)\n",
    "    to_index = { key: i for i, key in enumerate(unique_keys)}\n",
    "    index = np.asarray([to_index[j] for j in keys])\n",
    "    return unique_keys, index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Relation Block to express data\n",
    "See [Rendle 2013](http://www.vldb.org/pvldb/vol6/p337-rendle.pdf) how comlexity dcrease drastically in this case (and most cases with bipartite graph structure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RelationBlock.\n",
    "train_blocks = []\n",
    "test_blocks = []\n",
    "for source, target in [(df_train, train_blocks), (df_test, test_blocks)]:\n",
    "    unique_users, user_map = get_key_and_index(source.user_id) \n",
    "    target.append(\n",
    "        RelationBlock(user_map, augment_user_id(unique_users))\n",
    "    )\n",
    "    unique_movies, movie_map = get_key_and_index(source.movie_id)\n",
    "    target.append(\n",
    "        RelationBlock(movie_map, augment_movie_id(unique_movies))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alpha = 1.58 w0 = 3.64 : 100%|██████████| 100/100 [00:03<00:00, 28.63it/s]\n"
     ]
    }
   ],
   "source": [
    "fm = myfm.MyFMRegressor(rank=8)\n",
    "fm.fit(X_date_train, df_train.rating.values, X_rel=train_blocks,\n",
    "        grouping=grouping,\n",
    "        n_kept_samples=95, n_iter=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = fm.predict(X_date_test, test_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse=0.880576057570827, mae=0.6919916880160701\n"
     ]
    }
   ],
   "source": [
    "rmse = (\n",
    "    (test_predictions - df_test.rating.values)**2\n",
    ").mean() ** 0.5\n",
    "mae = np.abs(test_predictions - df_test.rating).mean()\n",
    "\n",
    "# Note the improvement from \"id_only\" case.\n",
    "# Compare this with methods like ones in https://paperswithcode.com/sota/collaborative-filtering-on-movielens-100k\n",
    "print('rmse={}, mae={}'.format(rmse, mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alpha = 1.23 w0 = 3.72 : 100%|██████████| 6/6 [00:05<00:00,  1.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# If we use the original data format, it takes much more!\n",
    "X_original_format = sps.hstack([\n",
    "    X_date_train\n",
    "] + [rel.data[rel.original_to_block] for rel in train_blocks])\n",
    "\n",
    "fm_rawformat = myfm.MyFMRegressor(rank=8).fit(X_original_format, df_train.rating,\n",
    "                                          grouping=grouping, n_iter=6, n_kept_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.46944695e-16,  1.80411242e-15, -8.04911693e-16, ...,\n",
       "         1.83186799e-15, -8.84708973e-17,  3.15025783e-15],\n",
       "       [ 2.02615702e-15,  1.72084569e-15, -4.32986980e-15, ...,\n",
       "         3.55271368e-15, -2.49800181e-16,  3.83026943e-15],\n",
       "       [-2.94209102e-15, -2.77555756e-17, -2.10942375e-15, ...,\n",
       "         1.04083409e-15, -2.59514632e-15,  2.66453526e-15],\n",
       "       ...,\n",
       "       [ 7.49400542e-16,  7.49400542e-16,  1.04083409e-15, ...,\n",
       "         8.88178420e-16, -4.99600361e-16,  6.10622664e-16],\n",
       "       [-2.10942375e-15,  7.07767178e-16,  5.55111512e-17, ...,\n",
       "         6.66133815e-16,  2.91433544e-16,  1.94289029e-15],\n",
       "       [-1.04083409e-15,  2.49800181e-16, -8.88178420e-16, ...,\n",
       "        -1.22124533e-15,  5.55111512e-16, -5.55111512e-17]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# They shoud be same up to floating point artifact.\n",
    "fm_rawformat.predictor_.samples[-1].V - fm.predictor_.samples[0].V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
