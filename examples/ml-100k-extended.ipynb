{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn import metrics\n",
    "import myfm\n",
    "from myfm import RelationBlock\n",
    "import pandas as pd\n",
    "from scipy import sparse as sps\n",
    "from mapper import DefaultMapper\n",
    "\n",
    "# read movielens 100k data.\n",
    "from movielens100k_data import MovieLens100kDataManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_manager = MovieLens100kDataManager()\n",
    "df_train, df_test = data_manager.load_rating(fold=1)\n",
    "\n",
    "user_info = data_manager.load_userinfo().set_index('user_id')\n",
    "user_info['age'] = user_info.age // 10 * 10\n",
    "user_info['zipcode'] = user_info.zipcode.str[0]\n",
    "\n",
    "user_info_ohe = OneHotEncoder(handle_unknown='ignore').fit(user_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zipcode</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age gender  occupation zipcode\n",
       "user_id                                \n",
       "1         20      M  technician       8\n",
       "2         50      F       other       9\n",
       "3         20      M      writer       3\n",
       "4         20      M  technician       4\n",
       "5         30      F       other       1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_to_internal = DefaultMapper(df_train.user_id.values)\n",
    "movie_to_internal = DefaultMapper(df_train.movie_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_be = OneHotEncoder(handle_unknown='ignore').fit(\n",
    "    df_train.timestamp.dt.date.values.reshape(-1, 1)\n",
    ")\n",
    "def categorize_date(df):\n",
    "    return date_be.transform(df.timestamp.dt.date.values[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_date_train = categorize_date(df_train)\n",
    "X_date_test  = categorize_date(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement flavor of SVD++\n",
    "# We add \"all users who have evaluated a movie in the train set\" or\n",
    "# \"all movies rated by a user\" as a feture of user/movie.\n",
    "use_iu = True # use implicit user feature\n",
    "use_ii = True # use implicit item feature\n",
    "use_user_info = False # use user information\n",
    "\n",
    "movie_vs_watched = dict()\n",
    "user_vs_watched = dict()\n",
    "for row in df_train.itertuples():\n",
    "    user_id = row.user_id\n",
    "    movie_id = row.movie_id\n",
    "    movie_vs_watched.setdefault(movie_id, list()).append(user_id)\n",
    "    user_vs_watched.setdefault(user_id, list()).append(movie_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup grouping\n",
    "feature_group_sizes = [\n",
    "    len(date_be.categories_[0]), # date\n",
    "    len(user_to_internal) # user ids\n",
    "] \n",
    "if use_iu:\n",
    "    feature_group_sizes.append(len(movie_to_internal))\n",
    "\n",
    "if use_user_info:\n",
    "    feature_group_sizes.extend([\n",
    "        len(c) for c in user_info_ohe.categories_ # user attributes\n",
    "    ])\n",
    "\n",
    "feature_group_sizes.append(\n",
    "    len(movie_to_internal) # movie ids\n",
    ")\n",
    "if use_ii:\n",
    "    feature_group_sizes.append(\n",
    "        len(user_to_internal) # all users who watched the movies\n",
    "    )\n",
    "\n",
    "grouping = [ i for i, size in enumerate(feature_group_sizes) for _ in range(size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given user/movie ids, add additional infos and return it as sparse\n",
    "def augment_user_id(user_ids):\n",
    "    if use_iu:\n",
    "        X = sps.lil_matrix((len(user_ids), len(user_to_internal) + len(movie_to_internal)))\n",
    "    else:\n",
    "        X = sps.lil_matrix((len(user_ids), len(user_to_internal)))\n",
    "    for index, user_id in enumerate(user_ids):\n",
    "        X[index, user_to_internal[user_id]] = 1\n",
    "        if not use_iu:\n",
    "            continue\n",
    "        watched_movies = user_vs_watched.get(user_id, [])\n",
    "        normalizer = 1 / max(len(watched_movies), 1) ** 0.5\n",
    "        for uid in watched_movies:\n",
    "            X[index, movie_to_internal[uid] + len(user_to_internal)] = normalizer\n",
    "    if use_user_info:\n",
    "        return sps.hstack(\n",
    "            [X.tocsr(), user_info_ohe.transform(user_info.reindex(user_ids))],\n",
    "            format='csr'\n",
    "        )\n",
    "    else:\n",
    "        return X.tocsr()\n",
    "\n",
    "def augment_movie_id(movie_ids):\n",
    "    if use_ii:\n",
    "        X = sps.lil_matrix((len(movie_ids), len(movie_to_internal)+len(user_to_internal)))\n",
    "    else:\n",
    "        X = sps.lil_matrix((len(movie_ids), len(movie_to_internal)))\n",
    "    for index, movie_id in enumerate(movie_ids):\n",
    "        X[index, movie_to_internal[movie_id]] = 1\n",
    "        if not use_ii:\n",
    "            continue\n",
    "        watched_users = movie_vs_watched.get(movie_id, [])\n",
    "        normalizer = 1 / max(len(watched_users), 1) ** 0.5\n",
    "        for uid in watched_users:\n",
    "            X[index, user_to_internal[uid] + len(movie_to_internal)] = normalizer\n",
    "    return X.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_and_index(keys):\n",
    "    unique_keys = np.unique(keys)\n",
    "    to_index = { key: i for i, key in enumerate(unique_keys)}\n",
    "    index = np.asarray([to_index[j] for j in keys])\n",
    "    return unique_keys, index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Relation Block to express data\n",
    "See [\\[Rendle 2013\\]](http://www.vldb.org/pvldb/vol6/p337-rendle.pdf) how comlexity dcrease drastically in this case (and most cases with bipartite graph structure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RelationBlock.\n",
    "train_blocks = []\n",
    "test_blocks = []\n",
    "for source, target in [(df_train, train_blocks), (df_test, test_blocks)]:\n",
    "    unique_users, user_map = get_key_and_index(source.user_id) \n",
    "    target.append(\n",
    "        RelationBlock(user_map, augment_user_id(unique_users))\n",
    "    )\n",
    "    unique_movies, movie_map = get_key_and_index(source.movie_id)\n",
    "    target.append(\n",
    "        RelationBlock(movie_map, augment_movie_id(unique_movies))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alpha = 1.58 w0 = 3.04  rmse_this: 0.96 mae_this: 0.75: 100%|██████████| 200/200 [00:08<00:00, 22.29it/s]\n"
     ]
    }
   ],
   "source": [
    "fm = myfm.MyFMRegressor(rank=8)\n",
    "fm.fit(X_date_train, df_train.rating.values, X_rel=train_blocks,\n",
    "        grouping=grouping, X_test=X_date_test, X_rel_test=test_blocks,\n",
    "        y_test=df_test.rating.values,\n",
    "        n_kept_samples=195, n_iter=200);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = fm.predict(X_date_test, test_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse=0.8883743119084084, mae=0.6985641283793332\n"
     ]
    }
   ],
   "source": [
    "rmse = (\n",
    "    (test_predictions - df_test.rating.values)**2\n",
    ").mean() ** 0.5\n",
    "mae = np.abs(test_predictions - df_test.rating).mean()\n",
    "\n",
    "# Note the improvement from \"id_only\" case.\n",
    "# Compare this with methods like ones in https://paperswithcode.com/sota/collaborative-filtering-on-movielens-100k\n",
    "print('rmse={}, mae={}'.format(rmse, mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alpha = 1.25 w0 = 3.41 : 100%|██████████| 6/6 [00:10<00:00,  1.83s/it]\n"
     ]
    }
   ],
   "source": [
    "# If we use the original data format, it takes much more!\n",
    "X_original_format = sps.hstack([\n",
    "    X_date_train\n",
    "] + [rel.data[rel.original_to_block] for rel in train_blocks], format='csr')\n",
    "\n",
    "fm_rawformat = myfm.MyFMRegressor(rank=8).fit(X_original_format, df_train.rating,\n",
    "                                          grouping=grouping, n_iter=6, n_kept_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.66453526e-15,  3.33066907e-16, -2.49800181e-15, ...,\n",
       "        -3.60822483e-16,  1.60982339e-15,  4.10782519e-15],\n",
       "       [ 5.77315973e-15,  5.49560397e-15,  1.69309011e-15, ...,\n",
       "         3.05311332e-15,  2.27595720e-15, -2.35228503e-15],\n",
       "       [-1.05020159e-14, -5.10702591e-15, -4.85722573e-16, ...,\n",
       "         2.10942375e-15,  1.36002321e-15,  1.54043445e-15],\n",
       "       ...,\n",
       "       [ 8.60422844e-16,  1.05471187e-15,  4.16333634e-16, ...,\n",
       "         2.77555756e-17, -5.55111512e-17, -4.99600361e-16],\n",
       "       [ 8.60422844e-16,  1.76247905e-15,  1.17614252e-15, ...,\n",
       "        -1.16573418e-15,  8.74300632e-16,  6.38378239e-16],\n",
       "       [ 1.36002321e-15, -2.77555756e-15,  1.77635684e-15, ...,\n",
       "         2.49800181e-16,  3.33066907e-16,  3.23352456e-15]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# They shoud be same up to floating point artifact.\n",
    "fm_rawformat.predictor_.samples[-1].V - fm.predictor_.samples[0].V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
