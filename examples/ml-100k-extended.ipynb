{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn import metrics\n",
    "import myfm\n",
    "from myfm import RelationBlock\n",
    "import pandas as pd\n",
    "from scipy import sparse as sps\n",
    "from mapper import DefaultMapper\n",
    "\n",
    "# read movielens 100k data.\n",
    "from movielens100k_data import MovieLens100kDataManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_manager = MovieLens100kDataManager()\n",
    "df_train, df_test = data_manager.load_rating(fold=1)\n",
    "\n",
    "user_info = data_manager.load_userinfo().set_index('user_id')\n",
    "user_info['age'] = user_info.age // 5 * 5\n",
    "user_info['zipcode'] = user_info.zipcode.str[0]\n",
    "user_info_ohe = OneHotEncoder(handle_unknown='ignore').fit(user_info)\n",
    "\n",
    "movie_info, movie_genres = data_manager.load_movieinfo()\n",
    "movie_info['release_year'] = [\n",
    "    str(x) for x in movie_info['release_date'].dt.year.fillna('NaN')\n",
    "] # hack to avoid NaN\n",
    "movie_info = movie_info[['movie_id', 'release_year'] + movie_genres].set_index('movie_id')\n",
    "movie_info_ohe = OneHotEncoder(handle_unknown='ignore').fit(movie_info.drop(columns=movie_genres))\n",
    "\n",
    "date_be = OneHotEncoder(handle_unknown='ignore').fit(\n",
    "    df_train.timestamp.dt.date.values.reshape(-1, 1)\n",
    ")\n",
    "def categorize_date(df):\n",
    "    return date_be.transform(df.timestamp.dt.date.values[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_to_internal = DefaultMapper(df_train.user_id.values)\n",
    "movie_to_internal = DefaultMapper(df_train.movie_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement side information and flavor of SVD++\n",
    "# We add \"all users who have evaluated a movie in the train set\" or\n",
    "# \"all movies rated by a user\" as a feture of user/movie.\n",
    "use_date = True # use date info or not\n",
    "use_iu = True # use implicit user feature\n",
    "use_ii = True # use implicit item feature\n",
    "use_user_info = True # use user information\n",
    "use_movie_info = True # use movie information\n",
    "\n",
    "movie_vs_watched = dict()\n",
    "user_vs_watched = dict()\n",
    "for row in df_train.itertuples():\n",
    "    user_id = row.user_id\n",
    "    movie_id = row.movie_id\n",
    "    movie_vs_watched.setdefault(movie_id, list()).append(user_id)\n",
    "    user_vs_watched.setdefault(user_id, list()).append(movie_id)\n",
    "\n",
    "if use_date:\n",
    "    X_date_train = categorize_date(df_train)\n",
    "    X_date_test  = categorize_date(df_test)\n",
    "else:\n",
    "    X_date_train, X_date_test = (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup grouping\n",
    "feature_group_sizes = []\n",
    "if use_date:\n",
    "    feature_group_sizes.append(\n",
    "        len(date_be.categories_[0]), # date\n",
    "    )\n",
    "\n",
    "feature_group_sizes.append(len(user_to_internal)) # user ids\n",
    "\n",
    "if use_iu:\n",
    "    feature_group_sizes.append(len(movie_to_internal))\n",
    "\n",
    "if use_user_info:\n",
    "    feature_group_sizes.extend([\n",
    "        len(c) for c in user_info_ohe.categories_ # user attributes\n",
    "    ])\n",
    "\n",
    "feature_group_sizes.append(len(movie_to_internal)) # movie ids\n",
    "                           \n",
    "if use_ii:\n",
    "    feature_group_sizes.append(\n",
    "        len(user_to_internal) # all users who watched the movies\n",
    "    )\n",
    "\n",
    "if use_movie_info:\n",
    "    feature_group_sizes.extend([\n",
    "        len(c) for c in movie_info_ohe.categories_ # user attributes\n",
    "    ])\n",
    "    feature_group_sizes.append(len(movie_genres))\n",
    "\n",
    "grouping = [ i for i, size in enumerate(feature_group_sizes) for _ in range(size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given user/movie ids, add additional infos and return it as sparse\n",
    "def augment_user_id(user_ids):\n",
    "    Xs = []\n",
    "    X_uid = sps.lil_matrix((len(user_ids), len(user_to_internal)))\n",
    "    for index, user_id in enumerate(user_ids):\n",
    "        X_uid[index, user_to_internal[user_id]] = 1\n",
    "    Xs.append(X_uid)\n",
    "    if use_iu:\n",
    "        X_iu = sps.lil_matrix((len(user_ids), len(movie_to_internal)))\n",
    "        for index, user_id in enumerate(user_ids):\n",
    "            watched_movies = user_vs_watched.get(user_id, [])\n",
    "            normalizer = 1 / max(len(watched_movies), 1) ** 0.5\n",
    "            for uid in watched_movies:\n",
    "                X_iu[index, movie_to_internal[uid]] = normalizer\n",
    "        Xs.append(X_iu)\n",
    "    if use_user_info:\n",
    "        Xs.append(user_info_ohe.transform(user_info.reindex(user_ids)))\n",
    "    return sps.hstack(Xs, format='csr')\n",
    "\n",
    "def augment_movie_id(movie_ids):\n",
    "    Xs = []\n",
    "    X_movie = sps.lil_matrix((len(movie_ids), len(movie_to_internal)))\n",
    "    for index, movie_id in enumerate(movie_ids):\n",
    "        X_movie[index, movie_to_internal[movie_id]] = 1\n",
    "    Xs.append(X_movie)\n",
    "    \n",
    "    if use_ii:\n",
    "        X_ii = sps.lil_matrix((len(movie_ids), len(user_to_internal)))\n",
    "        for index, movie_id in enumerate(movie_ids):\n",
    "            watched_users = movie_vs_watched.get(movie_id, [])\n",
    "            normalizer = 1 / max(len(watched_users), 1) ** 0.5\n",
    "            for uid in watched_users:\n",
    "                X_ii[index, user_to_internal[uid]] = normalizer\n",
    "        Xs.append(X_ii)    \n",
    "    \n",
    "    if use_movie_info:\n",
    "        Xs.append(movie_info_ohe.transform(movie_info.drop(columns=movie_genres).reindex(movie_ids)))\n",
    "        Xs.append(sps.csr_matrix(movie_info.reindex(movie_ids)[movie_genres].values))\n",
    "    return sps.hstack(Xs, format='csr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Relation Block to express data\n",
    "See [\\[Rendle 2013\\]](http://www.vldb.org/pvldb/vol6/p337-rendle.pdf) how comlexity dcrease drastically in this case (and most cases with bipartite graph structure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RelationBlock.\n",
    "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.unique.html\n",
    "train_blocks = []\n",
    "test_blocks = []\n",
    "for source, target in [(df_train, train_blocks), (df_test, test_blocks)]:\n",
    "    unique_users, user_map = np.unique(source.user_id, return_inverse=True)\n",
    "    target.append(\n",
    "        RelationBlock(user_map, augment_user_id(unique_users))\n",
    "    )\n",
    "    unique_movies, movie_map = np.unique(source.movie_id, return_inverse=True)\n",
    "    target.append(\n",
    "        RelationBlock(movie_map, augment_movie_id(unique_movies))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alpha = 1.57 w0 = 3.81  rmse_this: 0.95 mae_this: 0.74: 100%|██████████| 200/200 [00:11<00:00, 17.32it/s]\n"
     ]
    }
   ],
   "source": [
    "fm = myfm.MyFMRegressor(rank=8)\n",
    "fm.fit(\n",
    "    X_date_train, df_train.rating.values, X_rel=train_blocks,\n",
    "    grouping=grouping, X_test=X_date_test, X_rel_test=test_blocks,\n",
    "        y_test=df_test.rating.values,\n",
    "        n_kept_samples=195, n_iter=200);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse=0.8862637601998858, mae=0.6963833823580675\n"
     ]
    }
   ],
   "source": [
    "test_predictions = fm.predict(X_date_test, test_blocks)\n",
    "\n",
    "rmse = (\n",
    "    (test_predictions - df_test.rating.values)**2\n",
    ").mean() ** 0.5\n",
    "mae = np.abs(test_predictions - df_test.rating).mean()\n",
    "\n",
    "# Note the improvement from \"id_only\" case.\n",
    "# Compare this with methods like ones in https://paperswithcode.com/sota/collaborative-filtering-on-movielens-100k\n",
    "print('rmse={}, mae={}'.format(rmse, mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alpha = 1.30 w0 = 3.71 : 100%|██████████| 6/6 [00:14<00:00,  2.48s/it]\n"
     ]
    }
   ],
   "source": [
    "# If we use the original data format, it takes much more!\n",
    "X_original_format = []\n",
    "if use_date:\n",
    "    X_original_format.append(X_date_train)\n",
    "\n",
    "X_original_format.extend(\n",
    "    [rel.data[rel.original_to_block] for rel in train_blocks]\n",
    ")\n",
    "\n",
    "X_original_format = sps.hstack(X_original_format, format='csr')\n",
    "\n",
    "fm_rawformat = myfm.MyFMRegressor(rank=8).fit(X_original_format, df_train.rating,\n",
    "                                          grouping=grouping, n_iter=6, n_kept_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.94289029e-16,  2.35922393e-16, -1.05471187e-15, ...,\n",
       "        -1.11022302e-16, -2.12330153e-15, -1.68615122e-15],\n",
       "       [-1.38777878e-17,  1.80411242e-15, -9.02056208e-16, ...,\n",
       "         2.91433544e-16, -1.60982339e-15, -3.08086889e-15],\n",
       "       [ 4.16333634e-15,  1.22124533e-15, -1.55431223e-15, ...,\n",
       "         2.13717932e-15,  1.66533454e-15,  1.08246745e-15],\n",
       "       ...,\n",
       "       [ 1.49880108e-15,  8.32667268e-17,  1.04083409e-15, ...,\n",
       "         2.01227923e-16,  7.02563008e-16,  9.15933995e-16],\n",
       "       [ 8.20524204e-16,  4.16333634e-16,  1.13797860e-15, ...,\n",
       "         2.49800181e-16,  1.27675648e-15,  1.08593690e-15],\n",
       "       [ 2.85882429e-15, -2.60902411e-15, -2.94209102e-15, ...,\n",
       "        -1.26981758e-15,  1.80411242e-16,  1.87350135e-15]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# They shoud be same up to floating point artifact.\n",
    "fm_rawformat.predictor_.samples[-1].V - fm.predictor_.samples[0].V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
