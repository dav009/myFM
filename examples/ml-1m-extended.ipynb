{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn import metrics\n",
    "import myfm\n",
    "from myfm import RelationBlock\n",
    "import pandas as pd\n",
    "from scipy import sparse as sps\n",
    "from mapper import DefaultMapper\n",
    "\n",
    "# read movielens 100k data.\n",
    "from movielens1M_data import MovieLens1MDataManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_manager = MovieLens1MDataManager()\n",
    "df_train, df_test = data_manager.load_rating()\n",
    "\n",
    "user_to_internal = DefaultMapper(df_train.user_id.values)\n",
    "movie_to_internal = DefaultMapper(df_train.movie_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_be = OneHotEncoder(handle_unknown='ignore').fit(\n",
    "    df_train.timestamp.dt.date.values.reshape(-1, 1)\n",
    ")\n",
    "def categorize_date(df):\n",
    "    return date_be.transform(df.timestamp.dt.date.values[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement flavor of SVD++\n",
    "\n",
    "We add \"all users who have evaluated a movie in the train set\" as the movie's feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement side information and flavor of SVD++\n",
    "# We add \"all users who have evaluated a movie in the train set\" or\n",
    "# \"all movies rated by a user\" as a feture of user/movie.\n",
    "use_date = True # use date info or not\n",
    "use_iu = True # use implicit user feature\n",
    "use_ii = True # use implicit item feature\n",
    "\n",
    "movie_vs_watched = dict()\n",
    "user_vs_watched = dict()\n",
    "for row in df_train.itertuples():\n",
    "    user_id = row.user_id\n",
    "    movie_id = row.movie_id\n",
    "    movie_vs_watched.setdefault(movie_id, list()).append(user_id)\n",
    "    user_vs_watched.setdefault(user_id, list()).append(movie_id)\n",
    "\n",
    "if use_date:\n",
    "    X_date_train = categorize_date(df_train)\n",
    "    X_date_test  = categorize_date(df_test)\n",
    "else:\n",
    "    X_date_train, X_date_test = (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup grouping\n",
    "feature_group_sizes = []\n",
    "if use_date:\n",
    "    feature_group_sizes.append(\n",
    "        len(date_be.categories_[0]), # date\n",
    "    )\n",
    "\n",
    "feature_group_sizes.append(len(user_to_internal)) # user ids\n",
    "\n",
    "if use_iu:\n",
    "    feature_group_sizes.append(len(movie_to_internal))\n",
    "\n",
    "feature_group_sizes.append(len(movie_to_internal)) # movie ids\n",
    "                           \n",
    "if use_ii:\n",
    "    feature_group_sizes.append(\n",
    "        len(user_to_internal) # all users who watched the movies\n",
    "    )\n",
    "\n",
    "grouping = [ i for i, size in enumerate(feature_group_sizes) for _ in range(size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given user/movie ids, add additional infos and return it as sparse\n",
    "def augment_user_id(user_ids):\n",
    "    X = sps.lil_matrix((len(user_ids), len(user_to_internal) + (len(movie_to_internal) if use_iu else 0) ))\n",
    "    for index, user_id in enumerate(user_ids):\n",
    "        X[index, user_to_internal[user_id]] = 1\n",
    "        if not use_iu:\n",
    "            continue\n",
    "        watched_movies = user_vs_watched.get(user_id, [])\n",
    "        normalizer = 1 / max(len(watched_movies), 1) ** 0.5\n",
    "        for mid in watched_movies:\n",
    "            X[index, movie_to_internal[mid] + len(user_to_internal)] = normalizer\n",
    "    return X.tocsr()\n",
    "\n",
    "def augment_movie_id(movie_ids):\n",
    "    X = sps.lil_matrix((len(movie_ids), len(movie_to_internal)+ (len(user_to_internal) if use_ii else 0 )))\n",
    "    for index, movie_id in enumerate(movie_ids):\n",
    "        X[index, movie_to_internal[movie_id]] = 1\n",
    "        if not use_ii:\n",
    "            continue\n",
    "        watched_users = movie_vs_watched.get(movie_id, [])\n",
    "        normalizer = 1 / max(len(watched_users), 1) ** 0.5\n",
    "        for uid in watched_users:\n",
    "            X[index, user_to_internal[uid] + len(movie_to_internal)] = normalizer\n",
    "    return X.tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Relation Block to express data\n",
    "See [\\[Rendle 2013\\]](http://www.vldb.org/pvldb/vol6/p337-rendle.pdf) how comlexity dcrease drastically in this case (and most cases with bipartite graph structure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RelationBlock.\n",
    "train_blocks = []\n",
    "test_blocks = []\n",
    "for source, target in [(df_train, train_blocks), (df_test, test_blocks)]:\n",
    "    unique_users, user_map = np.unique(source.user_id, return_inverse=True)\n",
    "    target.append(\n",
    "        RelationBlock(user_map, augment_user_id(unique_users))\n",
    "    )\n",
    "    unique_movies, movie_map = np.unique(source.movie_id, return_inverse=True)\n",
    "    target.append(\n",
    "        RelationBlock(movie_map, augment_movie_id(unique_movies))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alpha = 1.88 w0 = 3.36 :  95%|█████████▍| 484/512 [17:03<01:00,  2.17s/it]"
     ]
    }
   ],
   "source": [
    "fm = myfm.MyFMRegressor(rank=32)\n",
    "fm.fit(X_date_train, df_train.rating.values, X_rel=train_blocks,\n",
    "        grouping=grouping,\n",
    "        n_iter=512);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 47s, sys: 180 ms, total: 2min 48s\n",
      "Wall time: 21.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_predictions = fm.predict(X_date_test, test_blocks, n_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse=0.8211322084108059, mae=0.6418122503539108\n"
     ]
    }
   ],
   "source": [
    "rmse = (\n",
    "    (test_predictions - df_test.rating.values)**2\n",
    ").mean() ** 0.5\n",
    "mae = np.abs(test_predictions - df_test.rating).mean()\n",
    "\n",
    "# Note the improvement from \"id_only\" case.\n",
    "# Compare this with methods like ones in https://paperswithcode.com/sota/collaborative-filtering-on-movielens-100k\n",
    "print('rmse={}, mae={}'.format(rmse, mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
